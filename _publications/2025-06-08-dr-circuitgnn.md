---
title: "DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs"
collection: publications
category: conferences
permalink: /publication/2025-06-08-dr-circuitgnn
excerpt: "DR-CircuitGNN accelerates the training of heterogeneous circuit graph neural networks on GPUs through novel data reuse strategies and GPU-optimized computation kernels."
date: 2025-06-08
venue: "ACM International Conference on Supercomputing (ICS)"
paperurl: "https://hpcrl.github.io/ICS2025-webpage/program/Proceedings_ICS25/ics25-76.pdf"
citation: 'Y. Luo, <b>S. Li</b>, J. Tao, K. G. Thorat, X. Xie, H. Peng, N. Xu, C. Ding, S. Huang. &quot;DR-CircuitGNN: Training Acceleration of Heterogeneous Circuit Graph Neural Network on GPUs.&quot; <i>In Proceedings of the 39th ACM International Conference on Supercomputing (ICS &apos;25)</i>, 2025.'
header:
  teaser: "publications/dr-circuitgnn.png"
---

## Abstract

We present **DR-CircuitGNN**, a GPU-accelerated training framework for heterogeneous circuit graph neural networks. By exploiting data reuse patterns unique to circuit graph structures and designing GPU-optimized computation kernels, our approach achieves substantial training speedup while maintaining model accuracy.

## Key Contributions

- Novel data reuse strategies tailored for heterogeneous circuit graph structures
- GPU-optimized kernels for circuit GNN training acceleration
- Comprehensive evaluation on real-world EDA circuit benchmarks

## Authors

Yuebo Luo, **Shiyang Li**, Junran Tao, Kiran Gautam Thorat, Xi Xie, Hongwu Peng, Nuo Xu, Caiwen Ding, Shaoyi Huang

*In Proceedings of the 39th ACM International Conference on Supercomputing (ICS '25), June 8-11, 2025, Salt Lake City, USA.*

![DR-CircuitGNN Architecture](/images/publications/dr-circuitgnn.png){: .align-center style="max-width: 100%;"}
